#' @title Predict Method for fastNaiveBayes fits
#' @description Uses a fastNaiveBayes model and a new data set to create the classifications.
#'     This can either be the raw probabilities generated by the fastNaiveBayes model or the classes themselves.
#'
#' @param object A fitted object of class "fastNaiveBayes".
#' @param newdata A numeric matrix with 1's and 0's to indicate the presence or absence of features. A Sparse dgcMatrix is also accepted.
#'     Note that if newdata contains features that were not encountered in the training data, these are omitted from the prediction.
#'     Furthermore, newdata can contain fewer features than encountered in the training data. In this case, newdata will be padded with
#'     extra columns all filled with 0's.
#' @param type If "raw", the conditional a-posterior probabilities for each class are returned, and the class with maximal probability else.
#' @param sparse Use a sparse Matrix? If true a sparse matrix will be constructed from x, which can give up to a 40\% speed up.
#'     It's possible to directly feed a sparse dgcMatrix as x, which will set this parameter to TRUE
#' @param ... Not used.
#' @return If type = 'class', a factor with classified class levels. If type = 'raw', a matrix with the predicted probabilities of
#'     each class, where each column in the matrix corresponds to a class level.
#'
#' @export
#' @import Matrix
#'
#' @details In the extremely unlikely case that two classes have the exact same estimated probability, the first encountered class
#'     is used as the classification and a warning is issued.
#'     The order of the classes is the same as the order in fastNaiveBayes$probability_table, which is a list.
#'
#'     Using a sparse matrix directly can be especially useful if it's necessary to use predict multiple times on the same matrix or
#'     on different subselections of the same initial matrix, see examples for further details.
#' @examples
#'     rm(list=ls())
#'     require(mlbench)
#'     require(Matrix)
#'
#'     # Load BreastCancer data
#'     data(BreastCancer)
#'     dim(BreastCancer)
#'     levels(BreastCancer$Class)
#'     head(BreastCancer)
#'
#'     # Convert to 0/1 dummies
#'     data_mat <- BreastCancer[,c("Class","Cl.thickness","Cell.size","Cell.shape")]
#'     col_counter <- ncol(data_mat)+1
#'     for(i in 2:ncol(data_mat)){
#'       for(val in unique(data_mat[,i])){
#'         data_mat[,col_counter] <- ifelse(data_mat[,i]==val,1,0)
#'         col_counter <- col_counter+1
#'       }
#'     }
#'
#'     # Construct y and sparse matrix
#'     y <- data_mat[,"Class"]
#'     data_mat <- data_mat[,setdiff(colnames(data_mat),c("Class","Cl.thickness",
#'     "Cell.size","Cell.shape"))]
#'
#'     sparse_data <- Matrix(as.matrix(data_mat), sparse = TRUE)
#'     data_mat <- as.matrix(data_mat)
#'
#'     # Example to estimate and predict once:
#'     model <- fastNaiveBayes(data_mat[1:400,], y[1:400], laplace = 1, sparse = TRUE)
#'     preds <- predict(model, newdata = data_mat[401:nrow(data_mat),], type = "class")
#'
#'     mean(preds!=y[401:length(y)])
#'
predict.fastNaiveBayes <- function(object, newdata, type=c("class","raw"), sparse = FALSE, ...){
  type <- match.arg(type)
  if(class(newdata)[1]!='dgCMatrix'){
    if(!is.matrix(newdata)){
      newdata <- as.matrix(newdata)
    }
    if(sparse){
      newdata <- Matrix(newdata, sparse = TRUE)
    }
  }else{
    sparse <- TRUE
  }

  names <- object$names
  distribution <- object$distribution

  other_names <- setdiff(names,colnames(newdata))
  if(length(other_names)>0){
    if(sparse){
      other_mat <- Matrix(0L, nrow = nrow(newdata), ncol = ncol(newdata), sparse = TRUE)
    } else {
      other_mat <- matrix(0L, nrow = nrow(newdata), ncol = ncol(newdata))
    }
    colnames(other_mat) <- other_names

    newdata <- cbind(newdata,other_mat)
  }
  newdata <- newdata[,names]
  data <- object$probability_table

  if(distribution=="bernoulli"){
    alt_data <- 1-newdata

    present <- log(data$present)
    nonpresent <- log(data$non_present)

    presence_prob <- newdata %*% t(present)
    nonpresence_prob <- alt_data %*% t(nonpresent)

    prob <- exp((presence_prob + nonpresence_prob))
  }
  if(distribution=="multinomial"){
    present <- log(data$present)
    presence_prob <- newdata %*% t(present)

    prob <- exp(presence_prob)
  }
  priors <- as.vector(object$priors)
  probs <- prob

  for(i in 1:length(priors)){
    probs[,i] <- probs[,i]*priors[i]
  }

  denom <- rowSums(probs)
  probs <- probs/denom

  if(type=='class'){
    if(any(max.col(probs, ties.method = "last") != max.col(probs, ties.method = "first"))){
      warning("Exact same estimated probabilities occured. First encountered class used as classification")
    }
    class <- names(object$priors)[max.col(probs, ties.method = "first")]
    return(as.factor(class))
  }
  return(probs)
}
